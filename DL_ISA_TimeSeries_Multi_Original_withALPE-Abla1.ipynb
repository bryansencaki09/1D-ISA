{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f3cd4-1a56-4c9f-af59-d48bc9d332f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Dropout, LayerNormalization, Bidirectional, LSTM, GRU, Layer, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Lambda, Reshape, Flatten, Input, MultiHeadAttention, Flatten, Concatenate, Add, Multiply, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733837d8-db79-4883-b1c3-ecfb06d5221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8db9fe-21d8-48de-b0f4-0959d59d23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_interpolate_with_mask(data):\n",
    "    \"\"\"\n",
    "    Simplified version with binary confidence:\n",
    "    - 1.0: Successfully interpolated (or originally valid)\n",
    "    - 0.0: Zero-filled (ALPE must handle)\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(data).astype(np.float32)\n",
    "    original_missing_mask = df.isnull()  # True = missing, False = valid\n",
    "    \n",
    "    print(f\"Originally missing values: {original_missing_mask.sum().sum()}\")\n",
    "\n",
    "    df_linear = df.interpolate(method='linear', limit_direction='both', axis=1, limit=None)\n",
    "    df_spline = df_linear.interpolate(method='spline', order=3, axis=1)\n",
    "    df_filled = df_spline.fillna(method='ffill', axis=1).fillna(method='bfill', axis=1)\n",
    "    \n",
    "    still_missing = df_filled.isnull()  # These will become zeros\n",
    "    \n",
    "    print(f\"Still missing after all interpolation: {still_missing.sum().sum()}\")\n",
    "    \n",
    "    # Fill remaining with zeros\n",
    "    df_final = df_filled.fillna(0)\n",
    "    df_interpolated_fin = df_final.clip(-1e6, 1e6)\n",
    "    \n",
    "    # binary mask\n",
    "    confidence_mask = np.ones_like(df_interpolated_fin.values, dtype=np.float32)\n",
    "    \n",
    "    # Only mark as 0.0 where we had to use fillna(0)\n",
    "    confidence_mask[still_missing.values] = 0.0\n",
    "    # Everything else (originally valid OR successfully interpolated) = 1.0\n",
    "    \n",
    "    result = df_interpolated_fin.values\n",
    "    mask = confidence_mask\n",
    "    \n",
    "    return result, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a21c9a-bb9c-43d4-abee-ab7e27ae00b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALPELayer(Layer):\n",
    "    \"\"\"\n",
    "    Attention-based Learnable Positional Encoding as a custom Keras Layer\n",
    "    \"\"\"\n",
    "    def __init__(self, n_timesteps=24, embed_dim=64, dropout_rate=0.5, name='alpe', **kwargs):\n",
    "        super(ALPELayer, self).__init__(name=name, **kwargs)\n",
    "        self.n_timesteps = n_timesteps\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        Build layer components\n",
    "        input_shape: tuple of (x_shape, mask_shape)\n",
    "        \"\"\"\n",
    "        feature_dim = input_shape[0][-1]  # Get feature dimension from x\n",
    "        \n",
    "        # Positional embedding layer\n",
    "        self.pos_embedding = Embedding(\n",
    "            input_dim=self.n_timesteps,\n",
    "            output_dim=self.embed_dim,\n",
    "            name=f'{self.name}_pos_embed')\n",
    "        \n",
    "        # 1D Convolution for learning interpolation patterns\n",
    "        self.conv1d = Conv1D(\n",
    "            filters=self.embed_dim,\n",
    "            kernel_size=3,\n",
    "            padding='same',\n",
    "            activation='relu',\n",
    "            name=f'{self.name}_conv1d')\n",
    "        \n",
    "        # ECA: Adaptive kernel size\n",
    "        k_size = max(3, int(abs((np.log2(self.embed_dim) + 1) / 2)))\n",
    "        if k_size % 2 == 0:\n",
    "            k_size += 1\n",
    "        \n",
    "        # ECA channel attention\n",
    "        self.eca_conv = Conv1D(\n",
    "            filters=1,\n",
    "            kernel_size=k_size,\n",
    "            padding='same',\n",
    "            activation='sigmoid',\n",
    "            name=f'{self.name}_eca')\n",
    "        \n",
    "        # Projection to match input feature dimension\n",
    "        if self.embed_dim != feature_dim:\n",
    "            self.projection = Dense(\n",
    "                units=feature_dim,\n",
    "                name=f'{self.name}_projection')\n",
    "        else:\n",
    "            self.projection = None\n",
    "\n",
    "        # Add dropout layer\n",
    "        self.dropout = Dropout(self.dropout_rate, name=f'{self.name}_dropout')\n",
    "        \n",
    "        # Store feature_dim for rebuild\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        # CRITICAL: Actually build the sub-layers\n",
    "        self.pos_embedding.build((None,))  # Embedding input shape\n",
    "        self.conv1d.build((None, self.n_timesteps, self.embed_dim))\n",
    "        \n",
    "        k_size = max(3, int(abs((np.log2(self.embed_dim) + 1) / 2)))\n",
    "        if k_size % 2 == 0:\n",
    "            k_size += 1\n",
    "        self.eca_conv.build((None, 1, self.embed_dim))\n",
    "        \n",
    "        if self.projection is not None:\n",
    "            self.projection.build((None, self.n_timesteps, self.embed_dim))\n",
    "        \n",
    "        self.dropout.build((None, self.n_timesteps, feature_dim))\n",
    "        \n",
    "        super(ALPELayer, self).build(input_shape)\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        inputs: [x, confidence_mask]\n",
    "            x: [batch, timesteps, features]\n",
    "            confidence_mask: [batch, timesteps]\n",
    "        \"\"\"\n",
    "        x, confidence_mask = inputs\n",
    "        \n",
    "        # ============================================================\n",
    "        # STEP 1: Create positional embeddings\n",
    "        # ============================================================\n",
    "        position_ids = tf.range(self.n_timesteps)\n",
    "        pos_embedding = self.pos_embedding(position_ids)  # [timesteps, embed_dim]\n",
    "        \n",
    "        # Broadcast to batch dimension\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        pos_embedding = tf.tile(\n",
    "            tf.expand_dims(pos_embedding, axis=0),\n",
    "            [batch_size, 1, 1]\n",
    "        )  # [batch, timesteps, embed_dim]\n",
    "        \n",
    "        # Apply conf mask\n",
    "        mask_expanded = tf.expand_dims(confidence_mask, axis=-1)  # [batch, timesteps, 1]\n",
    "        mask_expanded = tf.cast(mask_expanded, tf.float32)\n",
    "        \n",
    "        # Invert mask: confidence=1.0 → weight=0.0, confidence=0.0 → weight=1.0\n",
    "        alpe_weight = 1.0 - mask_expanded  # [batch, timesteps, 1]\n",
    "        \n",
    "        # Apply weight to positional encoding\n",
    "        masked_pe = pos_embedding * alpe_weight  # [batch, timesteps, embed_dim]\n",
    "\n",
    "        # Keras Conv1D expects [batch, timesteps, channels]\n",
    "        # masked_pe is already in correct shape: [batch, timesteps, embed_dim]\n",
    "        pe_conv = self.conv1d(masked_pe)  # [batch, timesteps, embed_dim]\n",
    "        \n",
    "        # For ECA on channels, we need to work on channel dimension\n",
    "        # Transpose to [batch, embed_dim, timesteps] for channel-wise operations\n",
    "        pe_transposed = tf.transpose(pe_conv, perm=[0, 2, 1])  # [batch, embed_dim, timesteps]\n",
    "        \n",
    "        # Global average pooling across time\n",
    "        gap = tf.reduce_mean(pe_transposed, axis=-1, keepdims=True)  # [batch, embed_dim, 1]\n",
    "        \n",
    "        # Reshape for Conv1D: [batch, embed_dim, 1] → need [batch, timesteps=embed_dim, channels=1]\n",
    "        gap_reshaped = tf.transpose(gap, perm=[0, 2, 1])  # [batch, 1, embed_dim]\n",
    "        \n",
    "        # Channel attention via 1D conv\n",
    "        channel_att = self.eca_conv(gap_reshaped)  # [batch, 1, embed_dim]\n",
    "        \n",
    "        # Reshape back: [batch, 1, embed_dim] → [batch, embed_dim, 1]\n",
    "        channel_att = tf.transpose(channel_att, perm=[0, 2, 1])  # [batch, embed_dim, 1]\n",
    "        \n",
    "        # Apply attention to pe_transposed [batch, embed_dim, timesteps]\n",
    "        pe_attended = pe_transposed * channel_att  # [batch, embed_dim, timesteps]\n",
    "        \n",
    "        # ============================================================\n",
    "        # STEP 5: Transpose back to [batch, timesteps, embed_dim]\n",
    "        # ============================================================\n",
    "        alpe_output = tf.transpose(pe_attended, perm=[0, 2, 1])  # [batch, timesteps, embed_dim]\n",
    "        \n",
    "        # Project to match input feature dimension if needed\n",
    "        if self.projection is not None:\n",
    "            alpe_output = self.projection(alpe_output)  # [batch, timesteps, features]\n",
    "\n",
    "        alpe_output = self.dropout(alpe_output, training=training)\n",
    "        \n",
    "        # ============================================================\n",
    "        # STEP 6: Residual connection with weighting\n",
    "        # ============================================================\n",
    "        # Now shapes match:\n",
    "        # alpe_output: [batch, timesteps, features]\n",
    "        # alpe_weight: [batch, timesteps, 1]\n",
    "        alpe_contribution = alpe_output * alpe_weight  # Broadcasting works!\n",
    "        x_enhanced = x + alpe_contribution\n",
    "        \n",
    "        return x_enhanced\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]  # Return x's shape\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(ALPELayer, self).get_config()\n",
    "        config.update({\n",
    "            'n_timesteps': self.n_timesteps,\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'dropout_rate': self.dropout_rate\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def get_build_config(self):\n",
    "        \"\"\"Return configuration needed to rebuild the layer during loading\"\"\"\n",
    "        build_config = {\n",
    "            'feature_dim': getattr(self, 'feature_dim', None)\n",
    "        }\n",
    "        return build_config\n",
    "    \n",
    "    def build_from_config(self, config):\n",
    "        \"\"\"Rebuild the layer's internal state from config\"\"\"\n",
    "        feature_dim = config.get('feature_dim')\n",
    "        if feature_dim is not None:\n",
    "            # Reconstruct input_shape that build() expects\n",
    "            input_shape = (\n",
    "                (None, self.n_timesteps, feature_dim),  # x_shape\n",
    "                (None, self.n_timesteps)  # mask_shape\n",
    "            )\n",
    "            self.build(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a42348f-848d-45e9-b131-ee72348d2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slope + elevation - fixed constraint\n",
    "\n",
    "def multi_focal_loss_slope_elevation_constraint(slope_values, elevation_values,\n",
    "                                                slope_threshold=40, elevation_threshold=2000,\n",
    "                                                alpha=0.25, gamma=2.0,\n",
    "                                                lambda_slope=0.4, lambda_elevation=0.3):\n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred_clipped = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "        ce = -y_true * tf.math.log(y_pred_clipped)\n",
    "        p_t = tf.where(tf.equal(y_true, 1), y_pred_clipped, 1 - y_pred_clipped)\n",
    "        \n",
    "        # Alpha weighting for class imbalance\n",
    "        alpha_t = tf.where(tf.equal(y_true[:, 1], 1), alpha, 1 - alpha)\n",
    "        \n",
    "        # Focal loss calculation\n",
    "        focal_weight = tf.expand_dims(alpha_t, 1) * tf.pow((1 - p_t), gamma)\n",
    "        focal_loss = focal_weight * ce\n",
    "        focal_loss = tf.reduce_mean(tf.reduce_sum(focal_loss, axis=1))\n",
    "        \n",
    "        # Get batch data\n",
    "        batch_size = tf.shape(y_pred)[0]\n",
    "        slope_batch = tf.gather(slope_values, tf.range(batch_size))\n",
    "        elevation_batch = tf.gather(elevation_values, tf.range(batch_size))\n",
    "        \n",
    "        # ISA predictions\n",
    "        isa_pred = y_pred[:, 0]\n",
    "        \n",
    "        # CONSTRAINT 1: Slope constraint\n",
    "        slope_mask = tf.cast(slope_batch > slope_threshold, tf.float32)\n",
    "        slope_penalty = tf.reduce_mean(tf.multiply(slope_mask, isa_pred))\n",
    "        \n",
    "        # CONSTRAINT 2: Elevation constraint\n",
    "        elevation_mask = tf.cast(elevation_batch > elevation_threshold, tf.float32)\n",
    "        elevation_penalty = tf.reduce_mean(tf.multiply(elevation_mask, isa_pred))\n",
    "        \n",
    "        # Combine all losses\n",
    "        total_loss = focal_loss + (lambda_slope * slope_penalty) + (lambda_elevation * elevation_penalty)\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a96bc9-21ce-40cd-a0c7-6e7c3d0705cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_multi_region_data(citarum_01_paths, citarum_02_paths, citarum_03_paths, jkt_paths):\n",
    "    def load_region_data_mask(paths):\n",
    "        # Load all dataframes for a region\n",
    "        ndvi_df = pd.read_csv(paths['ndvi'],delimiter=';', encoding='utf-8-sig',decimal=',')\n",
    "        mndwi_df = pd.read_csv(paths['mndwi'],delimiter=';', encoding='utf-8-sig',decimal=',')\n",
    "        ndbi_df = pd.read_csv(paths['ndbi'],delimiter=';', encoding='utf-8-sig',decimal=',')\n",
    "        ndbsi_df = pd.read_csv(paths['ndbsi'],delimiter=';', encoding='utf-8-sig',decimal=',')\n",
    "        cbi_df = pd.read_csv(paths['cbi'],delimiter=';', encoding='utf-8-sig',decimal=',')\n",
    "        uci_df = pd.read_csv(paths['uci'],delimiter=';', encoding='utf-8-sig',decimal=',')\n",
    "        print('NDVI shape before int:', ndvi_df.shape)\n",
    "        \n",
    "        # Extract features\n",
    "        ndvi_features = ndvi_df.iloc[:,5:-2].values\n",
    "        mndwi_features = mndwi_df.iloc[:,5:-2].values\n",
    "        ndbi_features = ndbi_df.iloc[:,5:-2].values\n",
    "        ndbsi_features = ndbsi_df.iloc[:,5:-2].values\n",
    "        cbi_features = cbi_df.iloc[:,5:-2].values\n",
    "        uci_features = uci_df.iloc[:,5:-2].values\n",
    "        print('NDVI shape after int:', ndvi_features.shape)\n",
    "        \n",
    "        # Clean and interpolate\n",
    "        ndvi_clean, ndvi_mask = clean_and_interpolate_with_mask(ndvi_features)\n",
    "        mndwi_clean, mndwi_mask = clean_and_interpolate_with_mask(mndwi_features)\n",
    "        ndbi_clean, ndbi_mask = clean_and_interpolate_with_mask(ndbi_features)\n",
    "        ndbsi_clean, ndbsi_mask = clean_and_interpolate_with_mask(ndbsi_features)\n",
    "        cbi_clean, cbi_mask = clean_and_interpolate_with_mask(cbi_features)\n",
    "        uci_clean, uci_mask = clean_and_interpolate_with_mask(uci_features)\n",
    "        \n",
    "        # Combine features\n",
    "        X = np.stack([ndvi_clean, mndwi_clean, ndbi_clean,\n",
    "                      ndbsi_clean,cbi_clean,uci_clean], axis=2)\n",
    "\n",
    "        print(f\"X after stacking: {X.shape}\")\n",
    "        \n",
    "        masks_stacked = np.stack([ndvi_mask,mndwi_mask,ndbi_mask,\n",
    "                                  ndbsi_mask,cbi_mask,uci_mask], axis=2)  # [n_samples, 24, 6]\n",
    "\n",
    "        timestep_confidence = masks_stacked.min(axis=2)  # [n_samples, 24]\n",
    "        print(f\"Confidence mask shape: {timestep_confidence.shape}\")\n",
    "        \n",
    "        # Get labels, slope and elevation\n",
    "        \n",
    "        labels = ndvi_df.iloc[:, 1].values\n",
    "        slope_values = ndvi_df.iloc[:, -2].values\n",
    "        elevation_values = ndvi_df.iloc[:, -1].values\n",
    "            \n",
    "        return X, labels, slope_values, elevation_values, timestep_confidence\n",
    "\n",
    "    # Load data for both regions\n",
    "    X_citarum_01, labels_citarum_01, slope_citarum_01, elev_citarum_01, mask_citarum_01 = load_region_data_mask(citarum_01_paths)\n",
    "    X_citarum_02, labels_citarum_02, slope_citarum_02, elev_citarum_02, mask_citarum_02 = load_region_data_mask(citarum_02_paths)\n",
    "    X_citarum_03, labels_citarum_03, slope_citarum_03, elev_citarum_03, mask_citarum_03 = load_region_data_mask(citarum_03_paths)\n",
    "    X_jkt, labels_jkt, slope_jkt, elev_jkt, mask_jkt = load_region_data_mask(jkt_paths)\n",
    "    \n",
    "    # Combine data from both regions\n",
    "    X_combined = np.concatenate([X_citarum_01, X_citarum_02, X_citarum_03, X_jkt], axis=0)\n",
    "    labels_combined = np.concatenate([labels_citarum_01, labels_citarum_02, labels_citarum_03, labels_jkt])\n",
    "    slope_combined = np.concatenate([slope_citarum_01, slope_citarum_02, slope_citarum_03, slope_jkt])\n",
    "    elev_combined = np.concatenate([elev_citarum_01, elev_citarum_02, elev_citarum_03, elev_jkt])\n",
    "    mask_combined = np.concatenate([mask_citarum_01, mask_citarum_02, mask_citarum_03, mask_jkt], axis=0)\n",
    "    \n",
    "    # Compute class weights on combined data\n",
    "    unique_classes = np.unique(labels_combined)\n",
    "\n",
    "    print(\"Labels combined shape:\", labels_combined.shape)\n",
    "    print(\"Labels combined type:\", type(labels_combined[0]) if len(labels_combined) > 0 else \"Empty\")\n",
    "    print(\"Unique classes from np.unique:\", unique_classes)\n",
    "    print(\"Unique classes type:\", type(unique_classes[0]) if len(unique_classes) > 0 else \"Empty\")\n",
    "    print(\"All unique values in labels_combined:\", set(labels_combined))\n",
    "    print(\"Any NaN values?\", np.any(pd.isna(labels_combined)))\n",
    "\n",
    "    # Check if there are any labels in y that aren't in classes\n",
    "    missing_labels = set(labels_combined) - set(unique_classes)\n",
    "    print(\"Labels in y but not in classes:\", missing_labels)\n",
    "    \n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=unique_classes,\n",
    "        y=labels_combined)\n",
    "    \n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    print(\"Class weights:\", class_weight_dict)\n",
    "    \n",
    "    y = np.asarray(labels_combined)\n",
    "    print(y)\n",
    "    print(len(np.unique(y)))\n",
    "    \n",
    "    # Encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_combined = label_encoder.fit_transform(labels_combined)\n",
    "    y_combined = to_categorical(y_combined)\n",
    "    print(y_combined)\n",
    "    \n",
    "    # Split combined data\n",
    "    X_train, X_test, y_train, y_test, slope_train, slope_test, elev_train, elev_test, mask_train, mask_test = train_test_split(X_combined, y_combined,\n",
    "                                                                                                                               slope_combined, elev_combined,\n",
    "                                                                                                                               mask_combined,\n",
    "                                                                                                                               test_size=0.3,random_state=42,\n",
    "                                                                                                                               stratify=y_combined)\n",
    "    \n",
    "    # Convert slope values to tensorflow constant\n",
    "    slope_train = tf.constant(slope_train, dtype=tf.float32)\n",
    "    slope_test = tf.constant(slope_test, dtype=tf.float32)\n",
    "\n",
    "    # Convert elev values to tensorflow constant\n",
    "    elev_train = tf.constant(elev_train, dtype=tf.float32)\n",
    "    elev_test = tf.constant(elev_test, dtype=tf.float32)\n",
    "    \n",
    "    return (X_train, X_test, y_train, y_test, label_encoder, class_weight_dict, slope_train, slope_test, elev_train, elev_test, mask_train, mask_test, y_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d6405-f526-4849-827c-b27981744750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "citarum_01_paths = {\n",
    "    'ndvi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_NDVI_ROI_01.csv',\n",
    "    'mndwi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_MNDWI_ROI_01.csv',\n",
    "    'ndbi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_NDBI_ROI_01.csv',\n",
    "    'ndbsi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_NDBSI_ROI_01.csv',\n",
    "    'cbi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_CBI_ROI_01.csv',\n",
    "    'uci': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_UCI_ROI_01.csv'\n",
    "}\n",
    "\n",
    "citarum_02_paths = {\n",
    "    'ndvi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_NDVI_ROI_02.csv',\n",
    "    'mndwi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_MNDWI_ROI_02.csv',\n",
    "    'ndbi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_NDBI_ROI_02.csv',\n",
    "    'ndbsi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_NDBSI_ROI_02.csv',\n",
    "    'cbi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_CBI_ROI_02.csv',\n",
    "    'uci': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_UCI_ROI_02.csv'\n",
    "}\n",
    "\n",
    "citarum_03_paths = {\n",
    "    'ndvi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_NDVI_ROI_03.csv',\n",
    "    'mndwi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_MNDWI_ROI_03.csv',\n",
    "    'ndbi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_NDBI_ROI_03.csv',\n",
    "    'ndbsi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_NDBSI_ROI_03.csv',\n",
    "    'cbi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_CBI_ROI_03.csv',\n",
    "    'uci': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_Citarum_UCI_ROI_03.csv'\n",
    "}\n",
    "\n",
    "jkt_paths = {\n",
    "    'ndvi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_DKI_NDVI.csv',\n",
    "    'mndwi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_DKI_MNDWI.csv',\n",
    "    'ndbi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_DKI_NDBI.csv',\n",
    "    'ndbsi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_DKI_NDBSI.csv',\n",
    "    'cbi': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_DKI_CBI.csv',\n",
    "    'uci': '/home/jupyter-bryan/ISA_Data/Sample_Points_ISA_DKI_UCI.csv'\n",
    "}\n",
    "\n",
    "# Prepare the combined data\n",
    "(X_train, X_test, y_train, y_test, label_encoder, class_weight_dict, slope_train, slope_test, elev_train, elev_test, mask_train, mask_test, y_combined) = prepare_multi_region_data(citarum_01_paths, \n",
    "                                                                                                                                                                                    citarum_02_paths, \n",
    "                                                                                                                                                                                    citarum_03_paths,\n",
    "                                                                                                                                                                                    jkt_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d475ec5-f58e-49df-994d-65ca093b4770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x, beta = 1):\n",
    "    return (x * sigmoid(beta * x))\n",
    "\n",
    "tf.keras.utils.get_custom_objects().update({'swish': swish})\n",
    "\n",
    "def ReshapeLayer(x):\n",
    "    shape = x.shape\n",
    "    # 1 possibility: H,W*channel\n",
    "    reshape = Reshape((shape[1],shape[2]))(x)\n",
    "    # 2 possibility: W,H*channel\n",
    "    # transpose = Permute((2,1,3))(x)\n",
    "    # reshape = Reshape((shape[1],shape[2]*shape[3]))(transpose)\n",
    "    return reshape\n",
    "\n",
    "# def self_attention_block(x, dim):\n",
    "#     q = Dense(dim)(x)\n",
    "#     k = Dense(dim)(x)\n",
    "#     v = Dense(dim)(x)\n",
    "#     scores = tf.matmul(q, k, transpose_b=True)\n",
    "#     attention_weights = tf.nn.softmax(scores / tf.sqrt(tf.cast(dim, tf.float32)))\n",
    "    \n",
    "#     return tf.matmul(attention_weights, v)\n",
    "\n",
    "def self_attention_block(x, dim):    \n",
    "    q = Dense(dim)(x)  # (batch, seq_len, dim)\n",
    "    k = Dense(dim)(x)  # (batch, seq_len, dim)\n",
    "    v = Dense(dim)(x)  # (batch, seq_len, dim)\n",
    "    \n",
    "    scores = tf.matmul(q, k, transpose_b=True)  # (batch, seq_len, seq_len)\n",
    "    scores = scores / tf.sqrt(tf.cast(dim, tf.float32))\n",
    "    \n",
    "    attention_weights = tf.nn.softmax(scores, axis=-1)  # (batch, seq_len, seq_len)\n",
    "    \n",
    "    output = tf.matmul(attention_weights, v)  # (batch, seq_len, dim)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def positional_encoding(seq_len, dim):\n",
    "    \"\"\"Sinusoidal positional encoding\"\"\"\n",
    "    position = np.arange(seq_len)[:, np.newaxis]\n",
    "    div_term = np.exp(np.arange(0, dim, 2) * -(np.log(10000.0) / dim))\n",
    "    \n",
    "    pos_encoding = np.zeros((seq_len, dim))\n",
    "    pos_encoding[:, 0::2] = np.sin(position * div_term)\n",
    "    pos_encoding[:, 1::2] = np.cos(position * div_term)\n",
    "    \n",
    "    return tf.constant(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "# # Usage:\n",
    "# pos_enc = positional_encoding(24, dim)\n",
    "# x = x + pos_enc  # Add before self-attention\n",
    "\n",
    "def transformer_attention_block(x, dim, num_heads=4):\n",
    "    # Add positional encoding\n",
    "    seq_len = x.shape[1]  # match time windo\n",
    "    pos_encoding = positional_encoding(seq_len, dim)\n",
    "    x_pos = x + pos_encoding\n",
    "    \n",
    "    # Multi-head self-attention\n",
    "    attn_output = MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=dim // num_heads\n",
    "    )(x_pos, x_pos)\n",
    "    \n",
    "    attn_output = Dropout(0.1)(attn_output)\n",
    "    \n",
    "    # Residual connection + Layer Norm\n",
    "    x = LayerNormalization(epsilon=1e-6)(x + attn_output)\n",
    "    \n",
    "    # Feed-forward network (optional but recommended)\n",
    "    ff = Dense(dim * 2, activation='relu')(x)\n",
    "    ff = Dense(dim)(ff)\n",
    "    ff = Dropout(0.2)(ff)\n",
    "    \n",
    "    # Another residual + norm\n",
    "    output = LayerNormalization(epsilon=1e-6)(x + ff)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d75857a-810a-4084-896c-d142f3d86260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "n_classes=len(label_encoder.classes_)\n",
    "\n",
    "def make_model(n_classes, n_timesteps=24, n_features=6):\n",
    "    input_layer = Input(shape=(n_timesteps, n_features))\n",
    "    confidence_mask_input = Input(shape=(n_timesteps,))\n",
    "    \n",
    "    x0a = Conv1D(16, 3, activation=\"swish\", padding = 'same')(input_layer)\n",
    "    x01a = Conv1D(16, 3, activation=\"swish\", padding = 'same')(x0a)\n",
    "    x01a = Conv1D(64, 3, activation=\"swish\", padding = 'same')(x01a)\n",
    "    \n",
    "    x02a = Conv1D(64, 3, activation=\"swish\", padding = 'same')(x01a)\n",
    "    x02a = Conv1D(64, 3, activation=\"swish\", padding = 'same')(x02a)\n",
    "    x02a = LayerNormalization()(x02a)\n",
    "\n",
    "    # x03a = Conv1D(64, 3, activation=\"swish\", padding = 'same')(x02a)\n",
    "    # x03a = Conv1D(64, 3, activation=\"swish\", padding = 'same')(x03a)\n",
    "\n",
    "    xa = tf.keras.layers.add([x01a, x02a])\n",
    "\n",
    "    x0b = Conv1D(16, 3, activation=\"swish\", padding = 'same')(input_layer)\n",
    "    x01b = Conv1D(16, 3, activation=\"swish\", padding = 'same')(x0b)\n",
    "    x01b = Conv1D(64, 3, activation=\"swish\", padding = 'same')(x01b)\n",
    "    \n",
    "    x02b = Conv1D(64, 3, activation=\"swish\", padding = 'same')(x01b)\n",
    "    x02b = Conv1D(64, 3, activation=\"swish\", padding = 'same')(x02b)\n",
    "    x02b = LayerNormalization()(x02b)\n",
    "\n",
    "    # x03b = Conv1D(64, 3, activation=\"swish\", padding = 'same')(x02b)\n",
    "    # x03b = Conv1D(64, 3, activation=\"swish\", padding = 'same')(x03b)\n",
    "\n",
    "    xb = tf.keras.layers.add([x01b, x02b])\n",
    "\n",
    "    conc_ = Concatenate()([xa, xb])\n",
    "\n",
    "    x0c = Conv1D(64, 3, activation=\"relu\", padding = 'same')(conc_)\n",
    "    # x0c = Conv1D(64, 3, activation=\"relu\", padding = 'same')(x0c)\n",
    "    x0c = LayerNormalization()(x0c)\n",
    "    \n",
    "    x_ft = Flatten()(x0c)\n",
    "\n",
    "    alpe_layer = ALPELayer(n_timesteps=n_timesteps, embed_dim=64, dropout_rate=0.5, name='alpe')\n",
    "    x0c_alpe = alpe_layer([x0c, confidence_mask_input])\n",
    "    \n",
    "    x_gru = Bidirectional(GRU(32, activation='tanh', return_sequences=False))(x0c_alpe)\n",
    "    # x_gru = Bidirectional(GRU(64, activation='tanh', return_sequences=False))(x_gru)\n",
    "    x_gru = LayerNormalization()(x_gru)\n",
    "\n",
    "    dim_conv1d = K.int_shape(x0c_alpe)[-1]\n",
    "    x_att = transformer_attention_block(x0c_alpe, dim_conv1d)\n",
    "    x_att = Flatten()(x_att)\n",
    "    \n",
    "    x_conc = Concatenate()([x_gru, x_ft, x_att])\n",
    "    x_conc = Dropout(0.5)(x_conc)\n",
    "    x_conc = Dense(64, activation='relu')(x_conc)\n",
    "    x_conc = Dropout(0.5)(x_conc)\n",
    "    \n",
    "    output_layer = Dense(n_classes, activation=\"softmax\")(x_conc)\n",
    "\n",
    "    return Model(inputs=[input_layer, confidence_mask_input], outputs=output_layer)\n",
    "\n",
    "model = make_model(n_classes=len(label_encoder.classes_))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=multi_focal_loss_slope_elevation_constraint(\n",
    "                    slope_train, elev_train,  \n",
    "                    slope_threshold=40, elevation_threshold=2000,\n",
    "                    alpha=0.25, gamma=2.0, lambda_slope=0.4, lambda_elevation=0.3),\n",
    "              optimizer=Adam(learning_rate=0.001), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "#               optimizer=Adam(learning_rate=0.001), \n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='/home/jupyter-bryan/ISA_Data/ISA_Citarum_Multi_Orig_withALPE_Abla1.keras',\n",
    "                             monitor='val_accuracy',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1,\n",
    "                             mode='max')\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy',\n",
    "                           patience=100,\n",
    "                           restore_best_weights=True,\n",
    "                           mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                              factor=0.1,\n",
    "                              patience=30, \n",
    "                              min_lr=0.00001)\n",
    "\n",
    "history = model.fit([X_train, mask_train],y_train, \n",
    "                    validation_data=([X_test, mask_test], y_test),\n",
    "                    batch_size=20,epochs=500, \n",
    "                    callbacks=[checkpoint, early_stop, reduce_lr])\n",
    "\n",
    "# history = model.fit([X_train, mask_train],y_train, \n",
    "#                     validation_data=([X_test, mask_test], y_test),\n",
    "#                     batch_size=20,epochs=500, \n",
    "#                     callbacks=[early_stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982fd132-e45c-4250-9e6b-94bc621308d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_expected = make_model(n_classes, n_timesteps=24, n_features=6)\n",
    "\n",
    "for i, layer in enumerate(model_expected.layers):\n",
    "    print(f\"{i+1:2d}. {layer.name:30s} | Type: {type(layer).__name__}\")\n",
    "\n",
    "print(f\"\\nTotal layers in current architecture: {len(model_expected.layers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea028a67-9361-4a71-9031-71d08b68ef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h5py\n",
    "\n",
    "# # Compare with saved model\n",
    "# model_path = '/home/jupyter-bryan/ISA_Data/ISA_Citarum_Multi_Orig_withALPE.keras'\n",
    "\n",
    "# print(\"\\n=== Saved Model Layers ===\")\n",
    "# with h5py.File(model_path, 'r') as f:\n",
    "#     if 'model_weights' in f:\n",
    "#         for i, layer_name in enumerate(f['model_weights'].keys()):\n",
    "#             print(f\"{i+1:2d}. {layer_name}\")\n",
    "#         print(f\"\\nTotal layers in saved file: {len(f['model_weights'].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86f38a-5a64-4629-b76f-b5b1934fd921",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train dtype:\", X_train.dtype)\n",
    "print(\"X_test dtype:\", X_test.dtype)\n",
    "print(\"y_train dtype:\", y_train.dtype)\n",
    "print(\"y_test dtype:\", y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7bb06-52e7-4c7b-b7b2-1bea3ee587ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = len(history.history['loss'])\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(n_epochs) #change it based on epoch needed to finish building the model\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef01919-bbb1-4c5a-81de-4b829f0fb21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classes = ['ISA','Dense Vegetation','Less Dense Vegetation', 'Bareland', 'Waterbody']\n",
    "\n",
    "y_pred = model.predict([X_test, mask_test])\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "dl_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "im = ax.imshow(dl_cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "ax.set(xticks=np.arange(dl_cm.shape[1]),\n",
    "        yticks=np.arange(dl_cm.shape[0]),\n",
    "        # ... and label them with the respective list entries\n",
    "        xticklabels=classes, yticklabels=classes,\n",
    "        title='Normalized Confusion Matrix',\n",
    "        ylabel='True label',\n",
    "        xlabel='Predicted label')\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "          rotation_mode=\"anchor\")\n",
    "\n",
    "fmt = '.2f'\n",
    "thresh = dl_cm.max() / 2.\n",
    "for i in range(dl_cm.shape[0]):\n",
    "    for j in range(dl_cm.shape[1]):\n",
    "        ax.text(j, i, format(dl_cm[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if dl_cm[i, j] > thresh else \"black\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e77701-26cb-4579-9d1e-602428d52e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_importance_predict(model, X_test, mask_test, y_test, feature_names, n_repeats=5):\n",
    "    X_test = np.array(X_test, dtype=np.float32)\n",
    "    \n",
    "    # Debug: Check shapes\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "    \n",
    "    # Get baseline predictions\n",
    "    baseline_pred = model.predict([X_test, mask_test], verbose=0)\n",
    "    print(f\"baseline_pred shape: {baseline_pred.shape}\")\n",
    "    \n",
    "    # Handle different y_test formats\n",
    "    if len(y_test.shape) == 1:\n",
    "        # If y_test is 1D (class indices), use it directly\n",
    "        y_true_classes = y_test\n",
    "    else:\n",
    "        # If y_test is one-hot encoded, convert to class indices\n",
    "        y_true_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Convert predictions to class indices\n",
    "    baseline_pred_classes = np.argmax(baseline_pred, axis=1)\n",
    "    \n",
    "    baseline_acc = np.mean(baseline_pred_classes == y_true_classes)\n",
    "    print(f\"Baseline accuracy: {baseline_acc:.4f}\")\n",
    "    \n",
    "    importance_scores = {}\n",
    "    \n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "        print(f\"Computing importance for {feature_name}...\")\n",
    "        \n",
    "        scores = []\n",
    "        for repeat in range(n_repeats):\n",
    "            X_test_perm = np.copy(X_test).astype(np.float32)\n",
    "            \n",
    "            # Permute feature i across all time steps\n",
    "            for t in range(X_test.shape[1]):\n",
    "                np.random.shuffle(X_test_perm[:, t, i])\n",
    "            \n",
    "            # Use predict instead of evaluate\n",
    "            perm_pred = model.predict([X_test_perm, mask_test], verbose=0)\n",
    "            perm_pred_classes = np.argmax(perm_pred, axis=1)\n",
    "            perm_acc = np.mean(perm_pred_classes == y_true_classes)\n",
    "            importance_drop = baseline_acc - perm_acc\n",
    "            scores.append(importance_drop)\n",
    "        \n",
    "        importance_scores[feature_name] = {\n",
    "            'mean': np.mean(scores),\n",
    "            'std': np.std(scores),\n",
    "            'scores': scores\n",
    "        }\n",
    "        \n",
    "        print(f\"{feature_name}: {np.mean(scores):.4f} ± {np.std(scores):.4f}\")\n",
    "    \n",
    "    return importance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cccc50-c14f-4b09-bf30-31453c0ae733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance_scores):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    features = list(importance_scores.keys())\n",
    "    means = [importance_scores[f]['mean'] for f in features]\n",
    "    stds = [importance_scores[f]['std'] for f in features]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(features, means, yerr=stds, capsize=5, alpha=0.7)\n",
    "    plt.ylabel('Importance Score (Accuracy Drop)')\n",
    "    plt.title('Feature Importance (Permutation-based)')\n",
    "    plt.xticks(rotation=0)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, mean in zip(bars, means):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.002, \n",
    "                f'{mean:.3f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.margins(x=0.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b88358-7eaa-488d-a706-6d8775835f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['NDVI', 'MNDWI', 'NDBI', 'NDBSI', 'CBI', 'UCI']\n",
    "importance_results = permutation_importance_predict(model, X_test, mask_test, y_test, feature_names, n_repeats=5)\n",
    "\n",
    "plot_feature_importance(importance_results)\n",
    "sorted_features = sorted(importance_results.items(), key=lambda x: x[1]['mean'], reverse=True)\n",
    "print(\"\\nFeature Importance Ranking:\")\n",
    "for i, (feature, scores) in enumerate(sorted_features, 1):\n",
    "    print(f\"{i}. {feature}: {scores['mean']:.4f} ± {scores['std']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f992b430-a810-4e7c-8b9d-0a909ea98152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
